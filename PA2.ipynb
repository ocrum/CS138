{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4.7 (Programming)\n",
    "\n",
    "Write a program for policy iteration and re-solve Jack’s car rental problem with the following changes:\n",
    " * One of Jack’s employees at the first location rides a bus home each night and lives near the second location. She is happy to shuttle one car to the second location for free. Each additional car still costs &#36;2, as do all cars moved in the other direction. \n",
    "  * In addition, Jack has limited parking space at each location. If more than 10 cars are kept overnight at a location (after any moving of cars), then an additional cost of &#36;4 must be incurred to use a second parking lot (independent of how many cars are kept there). \n",
    "    \n",
    "  These sorts of nonlinearities and arbitrary dynamics often occur in real problems and cannot easily be handled by optimization methods other than dynamic programming. To check your program, first replicate the results given for the original problem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa7aea004e8636f4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:06:44.898442Z",
     "start_time": "2023-10-21T02:06:44.876484Z"
    }
   },
   "id": "66457b2c7b7b294f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from P2 import Environment, Jack\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:06:45.646237Z",
     "start_time": "2023-10-21T02:06:44.900002Z"
    }
   },
   "id": "b50893d378f97d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training 0\n",
      "Policy Eval: 1 Change:191.16038246799107\n",
      "Policy Eval: 2 Change:131.62274411604793\n",
      "Policy Eval: 3 Change:88.1112578015969\n",
      "Policy Eval: 4 Change:65.9417721374804\n",
      "Policy Eval: 5 Change:51.89065063493791\n",
      "Policy Eval: 6 Change:40.08698444605085\n",
      "Policy Eval: 7 Change:31.188863441915373\n",
      "Policy Eval: 8 Change:24.671726101518914\n",
      "Policy Eval: 9 Change:20.50747025390632\n",
      "Policy Eval: 10 Change:17.126295037872637\n",
      "Policy Eval: 11 Change:14.26506479992372\n",
      "Policy Eval: 12 Change:11.853099840238315\n",
      "Policy Eval: 13 Change:9.82665021995399\n",
      "Policy Eval: 14 Change:8.129550363830106\n",
      "Policy Eval: 15 Change:6.712670792370602\n",
      "Policy Eval: 16 Change:5.533198922051383\n",
      "Policy Eval: 17 Change:4.553995136703691\n",
      "Policy Eval: 18 Change:3.7430246387605166\n",
      "Policy Eval: 19 Change:3.0728293712272716\n",
      "Policy Eval: 20 Change:2.5200211837737356\n",
      "Policy Eval: 21 Change:2.0647946930358216\n",
      "Policy Eval: 22 Change:1.6904662419544252\n",
      "Policy Eval: 23 Change:1.383046480307371\n",
      "Policy Eval: 24 Change:1.130852050783858\n",
      "Policy Eval: 25 Change:0.9241590262490149\n",
      "Policy Eval: 26 Change:0.7548982099847876\n",
      "Policy Eval: 27 Change:0.6163905424145355\n",
      "Policy Eval: 28 Change:0.5031196664986055\n",
      "Policy Eval: 29 Change:0.4105380671754233\n",
      "Policy Eval: 30 Change:0.3349029700438564\n",
      "Policy Eval: 31 Change:0.2731382275754868\n",
      "Policy Eval: 32 Change:0.22271863362180966\n",
      "Policy Eval: 33 Change:0.18157341313565212\n",
      "Policy Eval: 34 Change:0.14800598111827412\n",
      "Policy Eval: 35 Change:0.12062741948784605\n",
      "Policy Eval: 36 Change:0.09830146105736048\n",
      "Policy Eval: 37 Change:0.0800990848694596\n",
      "Policy Eval: 38 Change:0.06526111054381545\n",
      "Policy Eval: 39 Change:0.05316742968284416\n",
      "Policy Eval: 40 Change:0.04331173019511425\n",
      "Policy Eval: 41 Change:0.035280756440727146\n",
      "Policy Eval: 42 Change:0.028737308202323675\n",
      "Policy Eval: 43 Change:0.023406316319267262\n",
      "Policy Eval: 44 Change:0.019063446655820826\n",
      "Policy Eval: 45 Change:0.015525779501615489\n",
      "Policy Eval: 46 Change:0.01264419053347865\n",
      "Policy Eval: 47 Change:0.010297125919294103\n",
      "Policy Eval: 48 Change:0.008385518549971493\n",
      "CONVERGED in 48 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 1\n",
      "Policy Eval: 1 Change:64.21955806926587\n",
      "Policy Eval: 2 Change:4.527383760951125\n",
      "Policy Eval: 3 Change:1.9897616306875534\n",
      "Policy Eval: 4 Change:1.514016853721273\n",
      "Policy Eval: 5 Change:1.3056394305686467\n",
      "Policy Eval: 6 Change:1.075709403918836\n",
      "Policy Eval: 7 Change:0.876267383966308\n",
      "Policy Eval: 8 Change:0.7122242978795157\n",
      "Policy Eval: 9 Change:0.5786134201715072\n",
      "Policy Eval: 10 Change:0.4699960209932783\n",
      "Policy Eval: 11 Change:0.38174428050791676\n",
      "Policy Eval: 12 Change:0.31005495274376926\n",
      "Policy Eval: 13 Change:0.2518251313652513\n",
      "Policy Eval: 14 Change:0.2045297887751758\n",
      "Policy Eval: 15 Change:0.16611638833398956\n",
      "Policy Eval: 16 Change:0.13491723997708505\n",
      "Policy Eval: 17 Change:0.1095776103424555\n",
      "Policy Eval: 18 Change:0.08899709229399377\n",
      "Policy Eval: 19 Change:0.07228189910478022\n",
      "Policy Eval: 20 Change:0.05870608506143071\n",
      "Policy Eval: 21 Change:0.04768003529852649\n",
      "Policy Eval: 22 Change:0.03872486729079583\n",
      "Policy Eval: 23 Change:0.03145163700747844\n",
      "Policy Eval: 24 Change:0.025544448746927628\n",
      "Policy Eval: 25 Change:0.020746736488888473\n",
      "Policy Eval: 26 Change:0.016850121239770033\n",
      "Policy Eval: 27 Change:0.013685361009152075\n",
      "Policy Eval: 28 Change:0.011115000297422739\n",
      "Policy Eval: 29 Change:0.009027400162892718\n",
      "CONVERGED in 29 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 2\n",
      "Policy Eval: 1 Change:4.246455376296467\n",
      "Policy Eval: 2 Change:2.862715698404031\n",
      "Policy Eval: 3 Change:1.9417274695440483\n",
      "Policy Eval: 4 Change:1.3861676696812992\n",
      "Policy Eval: 5 Change:0.944458782430047\n",
      "Policy Eval: 6 Change:0.6240706982470101\n",
      "Policy Eval: 7 Change:0.4101838913077245\n",
      "Policy Eval: 8 Change:0.27362590223617644\n",
      "Policy Eval: 9 Change:0.1965215713712496\n",
      "Policy Eval: 10 Change:0.1481474757762271\n",
      "Policy Eval: 11 Change:0.11505823330810472\n",
      "Policy Eval: 12 Change:0.09384843102787954\n",
      "Policy Eval: 13 Change:0.07645088595756988\n",
      "Policy Eval: 14 Change:0.062228336452960775\n",
      "Policy Eval: 15 Change:0.05062570808149758\n",
      "Policy Eval: 16 Change:0.04117289564243265\n",
      "Policy Eval: 17 Change:0.03347804055437109\n",
      "Policy Eval: 18 Change:0.027217581874538155\n",
      "Policy Eval: 19 Change:0.02212589489278116\n",
      "Policy Eval: 20 Change:0.017985703266958808\n",
      "Policy Eval: 21 Change:0.014619683636340142\n",
      "Policy Eval: 22 Change:0.011883329110844443\n",
      "Policy Eval: 23 Change:0.009658985671478604\n",
      "CONVERGED in 23 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 3\n",
      "Policy Eval: 1 Change:0.5627124041279785\n",
      "Policy Eval: 2 Change:0.1724928445706837\n",
      "Policy Eval: 3 Change:0.08182212637757402\n",
      "Policy Eval: 4 Change:0.04968762169301044\n",
      "Policy Eval: 5 Change:0.03394484367777295\n",
      "Policy Eval: 6 Change:0.02272084385049311\n",
      "Policy Eval: 7 Change:0.014769472178272736\n",
      "Policy Eval: 8 Change:0.009588238953824657\n",
      "CONVERGED in 8 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 4\n",
      "Policy Eval: 1 Change:0.051916750966711334\n",
      "Policy Eval: 2 Change:0.010028881810285384\n",
      "Policy Eval: 3 Change:0.005512559876933665\n",
      "CONVERGED in 3 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? True\n",
      "Done Training\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = Environment(0)\n",
    "jack = Jack(0.9, environment)\n",
    "\n",
    "is_converged = False\n",
    "counter = 0\n",
    "\n",
    "policy_arr = []\n",
    "value_arr = []\n",
    "\n",
    "\n",
    "\n",
    "while not is_converged:\n",
    "    print(f\"Starting training {counter}\")\n",
    "    counter += 1\n",
    "\n",
    "    jack.policy_eval(tolerance=1e-2)\n",
    "    is_converged = jack.policy_imp()\n",
    "\n",
    "    policy_arr.append(jack.polices)\n",
    "    value_arr.append(jack.values)\n",
    "\n",
    "    jack.export_policy(counter, \"Test2\")\n",
    "    jack.export_value(counter, \"Test2\")\n",
    "\n",
    "print(\"Done Training\")\n",
    "os.system('osascript -e \\'display notification \"Script completed\" with title \"Jack Is Done!!\"\\'')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T04:51:50.211529Z",
     "start_time": "2023-10-21T04:05:27.792811Z"
    }
   },
   "id": "b88aea0e840fa474"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training 0\n",
      "Policy Eval: 1 Change:165.52587281543902\n",
      "Policy Eval: 2 Change:113.18584567989198\n",
      "Policy Eval: 3 Change:75.2308337820904\n",
      "Policy Eval: 4 Change:59.69452952565598\n",
      "Policy Eval: 5 Change:46.46731811069603\n",
      "Policy Eval: 6 Change:35.29073598948139\n",
      "Policy Eval: 7 Change:26.899102841682634\n",
      "Policy Eval: 8 Change:20.93242415908898\n",
      "Policy Eval: 9 Change:17.142949176891364\n",
      "Policy Eval: 10 Change:14.00357584782364\n",
      "Policy Eval: 11 Change:11.414316621128819\n",
      "Policy Eval: 12 Change:9.284993006521518\n",
      "Policy Eval: 13 Change:7.538278152207283\n",
      "Policy Eval: 14 Change:6.1089441538647975\n",
      "Policy Eval: 15 Change:4.942198426215327\n",
      "Policy Eval: 16 Change:3.992079495176881\n",
      "Policy Eval: 17 Change:3.2201121370597434\n",
      "Policy Eval: 18 Change:2.594191416992601\n",
      "Policy Eval: 19 Change:2.0876349001425183\n",
      "Policy Eval: 20 Change:1.6783613906787878\n",
      "Policy Eval: 21 Change:1.3481737807770173\n",
      "Policy Eval: 22 Change:1.082134069500114\n",
      "Policy Eval: 23 Change:0.8680226049052635\n",
      "Policy Eval: 24 Change:0.6958744265830319\n",
      "Policy Eval: 25 Change:0.5575853491065459\n",
      "Policy Eval: 26 Change:0.4465801223698236\n",
      "Policy Eval: 27 Change:0.3575349746633947\n",
      "Policy Eval: 28 Change:0.28614712644696283\n",
      "Policy Eval: 29 Change:0.22894438370713033\n",
      "Policy Eval: 30 Change:0.18312858437371915\n",
      "Policy Eval: 31 Change:0.14644739675634355\n",
      "Policy Eval: 32 Change:0.1170896955066496\n",
      "Policy Eval: 33 Change:0.09360042899612608\n",
      "Policy Eval: 34 Change:0.07481152062428009\n",
      "Policy Eval: 35 Change:0.059785904863076667\n",
      "Policy Eval: 36 Change:0.04777228536164557\n",
      "Policy Eval: 37 Change:0.038168619251791824\n",
      "Policy Eval: 38 Change:0.03049268532924998\n",
      "Policy Eval: 39 Change:0.024358390321140178\n",
      "Policy Eval: 40 Change:0.019456714285013277\n",
      "Policy Eval: 41 Change:0.015540400843804036\n",
      "Policy Eval: 42 Change:0.012411665800129867\n",
      "Policy Eval: 43 Change:0.009912335999956667\n",
      "CONVERGED in 43 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 1\n",
      "Policy Eval: 1 Change:86.33988227218111\n",
      "Policy Eval: 2 Change:8.071254040634642\n",
      "Policy Eval: 3 Change:4.025346718700462\n",
      "Policy Eval: 4 Change:3.054903382909572\n",
      "Policy Eval: 5 Change:2.5207243883116917\n",
      "Policy Eval: 6 Change:2.0321086364650682\n",
      "Policy Eval: 7 Change:1.6249687274108737\n",
      "Policy Eval: 8 Change:1.296253530066565\n",
      "Policy Eval: 9 Change:1.032935622719549\n",
      "Policy Eval: 10 Change:0.8226295710936711\n",
      "Policy Eval: 11 Change:0.6549232209308116\n",
      "Policy Eval: 12 Change:0.5213049281595659\n",
      "Policy Eval: 13 Change:0.41489953092423093\n",
      "Policy Eval: 14 Change:0.3301896826956181\n",
      "Policy Eval: 15 Change:0.26276356811109736\n",
      "Policy Eval: 16 Change:0.20910043230509245\n",
      "Policy Eval: 17 Change:0.1663938103901046\n",
      "Policy Eval: 18 Change:0.1324081039185785\n",
      "Policy Eval: 19 Change:0.10536317346088708\n",
      "Policy Eval: 20 Change:0.0838418961724301\n",
      "Policy Eval: 21 Change:0.06671631023419877\n",
      "Policy Eval: 22 Change:0.053088699090949376\n",
      "Policy Eval: 23 Change:0.04224463682726309\n",
      "Policy Eval: 24 Change:0.03361558755801752\n",
      "Policy Eval: 25 Change:0.0267491254588208\n",
      "Policy Eval: 26 Change:0.02128522806009414\n",
      "Policy Eval: 27 Change:0.016937406927809207\n",
      "Policy Eval: 28 Change:0.013477690082652316\n",
      "Policy Eval: 29 Change:0.01072467063198701\n",
      "Policy Eval: 30 Change:0.008533995908067027\n",
      "CONVERGED in 30 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 2\n",
      "Policy Eval: 1 Change:11.965239765753154\n",
      "Policy Eval: 2 Change:5.682055895781048\n",
      "Policy Eval: 3 Change:2.7200517067983583\n",
      "Policy Eval: 4 Change:1.3993196828027976\n",
      "Policy Eval: 5 Change:0.856320043647429\n",
      "Policy Eval: 6 Change:0.5918773626507914\n",
      "Policy Eval: 7 Change:0.4152256097992222\n",
      "Policy Eval: 8 Change:0.29816730834244254\n",
      "Policy Eval: 9 Change:0.219903482163204\n",
      "Policy Eval: 10 Change:0.1678698067957498\n",
      "Policy Eval: 11 Change:0.1341775479958187\n",
      "Policy Eval: 12 Change:0.10704480985504006\n",
      "Policy Eval: 13 Change:0.0853027474339001\n",
      "Policy Eval: 14 Change:0.06793061494187214\n",
      "Policy Eval: 15 Change:0.054073891906000426\n",
      "Policy Eval: 16 Change:0.04303264208164137\n",
      "Policy Eval: 17 Change:0.03424037856501627\n",
      "Policy Eval: 18 Change:0.027241753905514088\n",
      "Policy Eval: 19 Change:0.021672229866112502\n",
      "Policy Eval: 20 Change:0.017240674426489022\n",
      "Policy Eval: 21 Change:0.013714924273642737\n",
      "Policy Eval: 22 Change:0.010910010366615097\n",
      "Policy Eval: 23 Change:0.008678648728391636\n",
      "CONVERGED in 23 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 3\n",
      "Policy Eval: 1 Change:3.4580621269904555\n",
      "Policy Eval: 2 Change:0.3680754692302344\n",
      "Policy Eval: 3 Change:0.15162687639144679\n",
      "Policy Eval: 4 Change:0.0947141540867733\n",
      "Policy Eval: 5 Change:0.05731886857199697\n",
      "Policy Eval: 6 Change:0.03387899573772302\n",
      "Policy Eval: 7 Change:0.02004326432097514\n",
      "Policy Eval: 8 Change:0.012049462196614513\n",
      "Policy Eval: 9 Change:0.007470093277106571\n",
      "CONVERGED in 9 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 4\n",
      "Policy Eval: 1 Change:0.11272279766876636\n",
      "Policy Eval: 2 Change:0.005808012202010104\n",
      "CONVERGED in 2 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? True\n",
      "Done Training\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = Environment(1)\n",
    "jack = Jack(0.9, environment)\n",
    "\n",
    "is_converged = False\n",
    "counter = 0\n",
    "\n",
    "policy_arr_1 = []\n",
    "value_arr_1 = []\n",
    "\n",
    "while not is_converged:\n",
    "    print(f\"Starting training {counter}\")\n",
    "    counter += 1\n",
    "\n",
    "    jack.policy_eval(tolerance=1e-2)\n",
    "    is_converged = jack.policy_imp()\n",
    "\n",
    "    policy_arr_1.append(jack.polices)\n",
    "    value_arr_1.append(jack.values)\n",
    "\n",
    "    jack.export_policy(counter, \"new_ver_0\")\n",
    "    jack.export_value(counter, \"new_ver_0\")\n",
    "\n",
    "print(\"Done Training\")\n",
    "os.system('osascript -e \\'display notification \"Script completed\" with title \"Jack Is Done!!\"\\'')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:42:47.336634Z",
     "start_time": "2023-10-21T02:25:45.283152Z"
    }
   },
   "id": "ef780bbfe0653201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training 0\n",
      "Policy Eval: 1 Change:289.9056171725097\n",
      "Policy Eval: 2 Change:83.00090495173873\n",
      "Policy Eval: 3 Change:59.7140121299051\n",
      "Policy Eval: 4 Change:51.683681692257935\n",
      "Policy Eval: 5 Change:43.20220654388976\n",
      "Policy Eval: 6 Change:35.85120537173037\n",
      "Policy Eval: 7 Change:29.713952172020186\n",
      "Policy Eval: 8 Change:24.62313892051378\n",
      "Policy Eval: 9 Change:20.404200743188596\n",
      "Policy Eval: 10 Change:16.908135720938162\n",
      "Policy Eval: 11 Change:14.011093052080412\n",
      "Policy Eval: 12 Change:11.610431216845996\n",
      "Policy Eval: 13 Change:9.621099121848317\n",
      "Policy Eval: 14 Change:7.972619338505467\n",
      "Policy Eval: 15 Change:6.606590194163914\n",
      "Policy Eval: 16 Change:5.474616576852782\n",
      "Policy Eval: 17 Change:4.536595396783753\n",
      "Policy Eval: 18 Change:3.7592948300790567\n",
      "Policy Eval: 19 Change:3.115176995837203\n",
      "Policy Eval: 20 Change:2.581422355527195\n",
      "Policy Eval: 21 Change:2.139121271921681\n",
      "Policy Eval: 22 Change:1.7726040863537946\n",
      "Policy Eval: 23 Change:1.4688859805138463\n",
      "Policy Eval: 24 Change:1.217206955781478\n",
      "Policy Eval: 25 Change:1.0086506324194033\n",
      "Policy Eval: 26 Change:0.8358283638222019\n",
      "Policy Eval: 27 Change:0.6926174745920548\n",
      "Policy Eval: 28 Change:0.5739443489443943\n",
      "Policy Eval: 29 Change:0.4756046848025903\n",
      "Policy Eval: 30 Change:0.3941145454548973\n",
      "Policy Eval: 31 Change:0.3265869321916739\n",
      "Policy Eval: 32 Change:0.27062950480819836\n",
      "Policy Eval: 33 Change:0.2242598268699112\n",
      "Policy Eval: 34 Change:0.18583513274757024\n",
      "Policy Eval: 35 Change:0.1539941283382973\n",
      "Policy Eval: 36 Change:0.1276087638261174\n",
      "Policy Eval: 37 Change:0.10574426946834592\n",
      "Policy Eval: 38 Change:0.08762603907973698\n",
      "Policy Eval: 39 Change:0.07261218752825016\n",
      "Policy Eval: 40 Change:0.0601708103316696\n",
      "Policy Eval: 41 Change:0.049861139558117884\n",
      "Policy Eval: 42 Change:0.0413179284838634\n",
      "Policy Eval: 43 Change:0.034238511781097714\n",
      "Policy Eval: 44 Change:0.028372082827047507\n",
      "Policy Eval: 45 Change:0.023510808202274802\n",
      "Policy Eval: 46 Change:0.01948246471118864\n",
      "Policy Eval: 47 Change:0.01614433787682401\n",
      "Policy Eval: 48 Change:0.013378165911149154\n",
      "Policy Eval: 49 Change:0.011085950046435755\n",
      "Policy Eval: 50 Change:0.009186482603354307\n",
      "CONVERGED in 50 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 1\n",
      "Policy Eval: 1 Change:65.09167198652835\n",
      "Policy Eval: 2 Change:52.089545715618726\n",
      "Policy Eval: 3 Change:38.69960476633963\n",
      "Policy Eval: 4 Change:32.266401259989664\n",
      "Policy Eval: 5 Change:26.60194854784129\n",
      "Policy Eval: 6 Change:21.86479615003634\n",
      "Policy Eval: 7 Change:17.909718273823046\n",
      "Policy Eval: 8 Change:14.629542032215113\n",
      "Policy Eval: 9 Change:11.927977601557586\n",
      "Policy Eval: 10 Change:9.713816164128957\n",
      "Policy Eval: 11 Change:7.90481363409242\n",
      "Policy Eval: 12 Change:6.429754782502187\n",
      "Policy Eval: 13 Change:5.228475709940085\n",
      "Policy Eval: 14 Change:4.250904312589228\n",
      "Policy Eval: 15 Change:3.4557500476231553\n",
      "Policy Eval: 16 Change:2.8091561096343867\n",
      "Policy Eval: 17 Change:2.2834567777373422\n",
      "Policy Eval: 18 Change:1.8560926139876983\n",
      "Policy Eval: 19 Change:1.5086913085971219\n",
      "Policy Eval: 20 Change:1.2263020088561234\n",
      "Policy Eval: 21 Change:0.9967637924246446\n",
      "Policy Eval: 22 Change:0.810187826242668\n",
      "Policy Eval: 23 Change:0.658534227509108\n",
      "Policy Eval: 24 Change:0.535267031700414\n",
      "Policy Eval: 25 Change:0.43507320480671297\n",
      "Policy Eval: 26 Change:0.35363398635468\n",
      "Policy Eval: 27 Change:0.28743890261080196\n",
      "Policy Eval: 28 Change:0.23363452956266428\n",
      "Policy Eval: 29 Change:0.18990153326296877\n",
      "Policy Eval: 30 Change:0.15435471104979115\n",
      "Policy Eval: 31 Change:0.12546173587713838\n",
      "Policy Eval: 32 Change:0.10197710675595317\n",
      "Policy Eval: 33 Change:0.08288846073980949\n",
      "Policy Eval: 34 Change:0.06737293391904586\n",
      "Policy Eval: 35 Change:0.05476169013388699\n",
      "Policy Eval: 36 Change:0.04451108959528938\n",
      "Policy Eval: 37 Change:0.0361792539582666\n",
      "Policy Eval: 38 Change:0.02940701804402579\n",
      "Policy Eval: 39 Change:0.023902447264049442\n",
      "Policy Eval: 40 Change:0.01942825294645445\n",
      "Policy Eval: 41 Change:0.01579156345451338\n",
      "Policy Eval: 42 Change:0.012835609920898605\n",
      "Policy Eval: 43 Change:0.010432968356440142\n",
      "Policy Eval: 44 Change:0.008480066750280457\n",
      "CONVERGED in 44 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 2\n",
      "Policy Eval: 1 Change:17.20808328149235\n",
      "Policy Eval: 2 Change:6.987336683993249\n",
      "Policy Eval: 3 Change:5.297568669532552\n",
      "Policy Eval: 4 Change:4.4706954433479495\n",
      "Policy Eval: 5 Change:3.764792054460827\n",
      "Policy Eval: 6 Change:3.0396230172498235\n",
      "Policy Eval: 7 Change:2.424035727189562\n",
      "Policy Eval: 8 Change:1.9346356793126915\n",
      "Policy Eval: 9 Change:1.5518026412541985\n",
      "Policy Eval: 10 Change:1.251211889573483\n",
      "Policy Eval: 11 Change:1.0130038375626782\n",
      "Policy Eval: 12 Change:0.8225538959902678\n",
      "Policy Eval: 13 Change:0.6692418299059\n",
      "Policy Eval: 14 Change:0.5452258116665689\n",
      "Policy Eval: 15 Change:0.4445763731014267\n",
      "Policy Eval: 16 Change:0.36271151378821287\n",
      "Policy Eval: 17 Change:0.29602943039742513\n",
      "Policy Eval: 18 Change:0.24166333034713716\n",
      "Policy Eval: 19 Change:0.19731154285580033\n",
      "Policy Eval: 20 Change:0.16111521962557163\n",
      "Policy Eval: 21 Change:0.1315672589166752\n",
      "Policy Eval: 22 Change:0.10744260406272588\n",
      "Policy Eval: 23 Change:0.08774379351859807\n",
      "Policy Eval: 24 Change:0.07165779740194012\n",
      "Policy Eval: 25 Change:0.05852145223991556\n",
      "Policy Eval: 26 Change:0.04779359251301685\n",
      "Policy Eval: 27 Change:0.03903247965592982\n",
      "Policy Eval: 28 Change:0.03187746768958277\n",
      "Policy Eval: 29 Change:0.02603408142772423\n",
      "Policy Eval: 30 Change:0.02126185725489904\n",
      "Policy Eval: 31 Change:0.01736442691128559\n",
      "Policy Eval: 32 Change:0.014181426323261803\n",
      "Policy Eval: 33 Change:0.011581891766468289\n",
      "Policy Eval: 34 Change:0.009458868199885728\n",
      "CONVERGED in 34 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 3\n",
      "Policy Eval: 1 Change:2.246242879627289\n",
      "Policy Eval: 2 Change:0.31296083432141586\n",
      "Policy Eval: 3 Change:0.13402240209620686\n",
      "Policy Eval: 4 Change:0.10540932526714641\n",
      "Policy Eval: 5 Change:0.08591989211856799\n",
      "Policy Eval: 6 Change:0.06841725820004285\n",
      "Policy Eval: 7 Change:0.05476635452384926\n",
      "Policy Eval: 8 Change:0.044205138656025156\n",
      "Policy Eval: 9 Change:0.03586908323075022\n",
      "Policy Eval: 10 Change:0.029179120639582834\n",
      "Policy Eval: 11 Change:0.023763054015034868\n",
      "Policy Eval: 12 Change:0.019361298801527482\n",
      "Policy Eval: 13 Change:0.01577806343254906\n",
      "Policy Eval: 14 Change:0.01285912640571496\n",
      "Policy Eval: 15 Change:0.010480617292728311\n",
      "Policy Eval: 16 Change:0.00854221641463937\n",
      "CONVERGED in 16 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? False\n",
      "Starting training 4\n",
      "Policy Eval: 1 Change:0.048395383662750646\n",
      "Policy Eval: 2 Change:0.007427386716472029\n",
      "CONVERGED in 2 iterations\n",
      "Starting policy improvement\n",
      "Finished policy improvement. Stable? True\n",
      "Done Training\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = Environment(2)\n",
    "jack = Jack(0.9, environment)\n",
    "\n",
    "is_converged = False\n",
    "counter = 0\n",
    "\n",
    "policy_arr_2 = []\n",
    "value_arr_2 = []\n",
    "\n",
    "while not is_converged:\n",
    "    print(f\"Starting training {counter}\")\n",
    "    counter += 1\n",
    "\n",
    "    jack.policy_eval(tolerance=1e-2)\n",
    "    is_converged = jack.policy_imp()\n",
    "\n",
    "    policy_arr_2.append(jack.polices)\n",
    "    value_arr_2.append(jack.values)\n",
    "\n",
    "    jack.export_policy(counter, \"extra_0\")\n",
    "    jack.export_value(counter, \"extra_0\")\n",
    "\n",
    "print(\"Done Training\")\n",
    "os.system('osascript -e \\'display notification \"Script completed\" with title \"Jack Is Done!!\"\\'')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T04:04:30.510811Z",
     "start_time": "2023-10-21T02:51:28.666784Z"
    }
   },
   "id": "2d55a15abdbccadc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
